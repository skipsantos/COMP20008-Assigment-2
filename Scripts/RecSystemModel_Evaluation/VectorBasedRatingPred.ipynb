{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \r\nimport pandas as pd\r\nfrom sklearn.feature_extraction.text import CountVectorizer\r\nfrom sklearn.metrics.pairwise import cosine_similarity\r\n\r\n#function to load the data \r\ndef load_data(input_path):\r\n    # Load and return all datasets\r\n    users = pd.read_csv(os.path.join(input_path, 'BX-NewBooksUsers.csv'))\r\n    ratings = pd.read_csv(os.path.join(input_path, 'BX-Ratings.csv'))\r\n    books_old = pd.read_csv(os.path.join(input_path, 'BX-Books.csv'))\r\n    new_books = pd.read_csv(os.path.join(input_path, 'BX-NewBooks.csv'))\r\n    books = pd.concat([books_old, new_books]).drop_duplicates(subset=[\"Book-Title\"], keep='first')\r\n    return users, ratings, books, books_old, new_books\r\n\r\n#function to create tags and vectorize the data\r\ndef prepare_data(books):\r\n    # Prepare book data by creating a tags column and vectorizing it\r\n    books['tags'] = books['Book-Author'] + \" \" + books['Book-Title'] + \" \" + books['Book-Publisher'] + \" \" + books['Year-Of-Publication'].astype(str)\r\n    cv = CountVectorizer(max_features=500, stop_words=\"english\")\r\n    vectors = cv.fit_transform(books[\"tags\"]).toarray()\r\n    return vectors\r\n\r\n#function to run cosine similrity and return first 20 similar books\r\ndef find_similar_books(book_id, books, new_books, vectors):\r\n    # Calculate similarity and find similar books\r\n    similarity = cosine_similarity(vectors)\r\n    try:\r\n        book_idx = books.index[books['ISBN'] == book_id].tolist()[0]\r\n        similar_books = sorted(list(enumerate(similarity[book_idx])), key=lambda x: x[1], reverse=True)[1:20]\r\n        return similar_books\r\n    except IndexError:\r\n        print(\"Book ID not found in dataset.\")\r\n        return []\r\n\r\n#function to predict the rating of the given book \r\ndef predict_rating(user_id, book_id, ratings, books, books_old, similar_books):\r\n    # Recommend books based on the cosine similarity scores\r\n    rating_sims = [] #for predicted ratings\r\n    mean_sims=[] #for mean similarity score\r\n    printed_books = 0\r\n    \r\n    book_isbn = books[books['ISBN']==book_id]\r\n    book_title=book_isbn[\"Book-Title\"].values\r\n    print(f\"recommended books for people who have read {book_title[0]}:\\n\")\r\n    \r\n    for idx, sim_score in similar_books:\r\n        similar_isbn = books.iloc[idx]['ISBN']\r\n        #we can only get ratings if the ISBN for the simialar book is in the old_books dataset\r\n        if similar_isbn in books_old['ISBN'].values:\r\n            book_title = books.iloc[idx]['Book-Title']\r\n            book_author = books.iloc[idx]['Book-Author']\r\n            isbn_ratings = ratings[ratings[\"ISBN\"] == similar_isbn]\r\n            #check if it actually has ratings\r\n            if not isbn_ratings.empty:\r\n                mean_rating = isbn_ratings['Book-Rating'].mean() \r\n                adjusted_score = mean_rating * sim_score #find predicted rating for the similar book\r\n                rating_sims.append(float(adjusted_score)) #push the predicted score of the book to the array\r\n                mean_sims.append(float(sim_score)) #push mean similarity score\r\n                if printed_books < 5: #only print the first five similar books\r\n                    printed_books= printed_books+1\r\n                    print(f\"\\n{book_title} by {book_author} (Adjusted Score: {adjusted_score:.2f}) Sim Score = {sim_score:.4f}\")\r\n    if rating_sims:\r\n        # find mean of similarity and predicted_rating\r\n        avg_score = sum(rating_sims) / len(rating_sims)\r\n        mean_sim = sum(mean_sims) / len(mean_sims) \r\n        average_adjusted_score = (avg_score/mean_sim) #mapping back to 1 and 10 \r\n        book_isbn = books[books['ISBN']==book_id]\r\n        book_title=book_isbn[\"Book-Title\"].values\r\n        print(f\"\\nPredicted Score for {book_title[0]}: {average_adjusted_score:.2f}\") #print the predicted rating for given ISBN\r\n    return average_adjusted_score\r\n\r\n#function to find similar books and run predict on them\r\ndef predict(user_id, book_id, input_path):\r\n    users, ratings, books, books_old, new_books = load_data(input_path)\r\n    vectors = prepare_data(books)\r\n    similar_books = find_similar_books(book_id, books, new_books, vectors)\r\n    #if similar_books exist:\r\n    if similar_books:\r\n        avg_score = predict_rating(user_id, book_id, ratings, books, books_old, similar_books)\r\n        return avg_score\r\n    \r\ndef main(input_path):\r\n    #input_path = '/kaggle/input/booksusers'\r\n    predict(276762, \"0836218655\", input_path)\r\n\r\nmain('/kaggle/input/booksusers') #change it with your input path\r\n\r\n\r\n#change all of this with your input path for the pre-processed data\r\nusers = pd.read_csv('/kaggle/input/booksusers/BX-NewBooksUsers.csv')\r\nratings = pd.read_csv('/kaggle/input/booksusers/BX-Ratings.csv')\r\nbooks_old = pd.read_csv('/kaggle/input/booksusers/BX-Books.csv')\r\nnew_books = pd.read_csv('/kaggle/input/booksusers/BX-NewBooks.csv')\r\nnew_ratings = pd.read_csv('/kaggle/input/booksusers/BX-NewBooksRatings.csv')\r\n\r\nnew_ratings = new_ratings.head(10)\r\nisbn_vals = new_ratings[\"ISBN\"].values\r\ninput_path = '/kaggle/input/booksusers'\r\nrated_vals =[]\r\n\r\nactual_rates = new_ratings[\"Book-Rating\"].values #store actual values in array\r\n# run the function to predict the rating on the new books using the ISBNs of the same 100 selected new books \r\nfor i in isbn_vals:\r\n    pred_rating = predict(276762, str(i), input_path)\r\n    rated_vals.append(pred_rating)\r\nprint(rated_vals)\r\n\r\n#removes None from the array and replaces it with the mean\r\nnew_vals = []\r\n# We ran the program on the 1st 100 files in the dataset and saved the predicted values in the array:\r\npred_vals =[6.780299296868589, 6.883247181439865, 6.491441234512691, 5.092070939010894, 4.825337676616067, 5.8903670359152205, 6.670018546736091, 6.797327773128877, 6.215137741899781, 7.31106536571452, 6.558625729282679, 6.765252514524346, 7.056554333195935, 6.489950526422479, 6.11304471064381, 6.90733517567666, 5.854211718175123, None, 5.71726227903091, 5.555935030769504, 5.947359844298425, 5.5693953559734535, 6.298941973637561, 6.569553759170713, 5.855623511015049, 5.589480884780647, 5.735125250401022, 6.814945942344286, 6.656405412048171, 5.751456260313828, 6.448911664036413, 5.538093664195579, 5.364355158664125, None, 6.362038264211947, 5.690925830637674, None, None, 6.57754404581198, 6.729824359998354, None, 5.516965715774633, 5.495337900117775, 5.377176963447635, 6.696485825415812, 5.9986595516771, 6.55900460775128, 5.8173472607226, None, 5.7606629197717965, 5.20461164534942, 5.817852828551997, 6.527926153214571, 6.087540539181012, 5.371760452991041, 6.797797595201976, None, 6.680991920934416, 5.920927699221332, 6.9678605136471115, 6.848365566172391, 5.008352686552237, 6.42738775445907, 4.0941123938064905, None, 6.643643687111696, 6.8091837363328205, 6.377581414109571, 7.090732744920675, 6.744665255271885, None, 6.1956046768719615, 6.93372600781848, 6.401923654948151, 5.6985439155188065, 5.687613695343721, 6.089168203811976, 5.6270839936187365, 7.164204005342974, 5.584881826489261, 6.109526555145154, 6.018047386376358, 6.3826210822445155, 6.729495719702318, 5.954620442798883, 7.292383333929558, 6.666142063485205, 6.855348094937719, None, 6.242415158020659, 6.5930687637163095, None, 6.417388392386845, 6.748462021489844, 6.4167945708357035, 6.651397253021553, None, 6.817983103236857, 6.314321711121775, 6.535561447372781]\r\ntotal = sum(x for x in pred_vals if x is not None)\r\nmean_vals = total/100\r\nfor i in range(0,len(pred_vals)) :\r\n    if pred_vals[i] is not None:\r\n        new_vals.append(pred_vals[i])\r\n    else:\r\n        new_vals.append(mean_vals)\r\n\r\nnew_ratings = new_ratings.head(100)\r\nactual_rates = new_ratings[\"Book-Rating\"].values #actual ratings for the first 100 entries\r\ny_actual = actual_rates\r\ny_predicted = new_vals # predicted ratings for the first 100 entries\r\n\r\n#Find and print RMSE\r\nMSE = np.square(np.subtract(actual_rates,new_vals)).mean()  \r\nRMSE = math.sqrt(MSE)\r\nprint(\"Root Mean Square Error:\\n\")\r\nprint(RMSE)\r\n\r\n#A first attemp to recommend books\r\n'''\r\n#reccomends books to user 27688 based on their readings  ##ignore\r\nuser_id=276688 # selected this user as they have a lot of ratings\r\nuser_rating = ratings[ratings['User-ID']==user_id]\r\nsorted_df = user_rating.sort_values(by='Book-Rating', ascending=False) # get their highest rated books\r\nsorted_df = sorted_df.head(3)\r\nbest_books = sorted_df[\"ISBN\"].values\r\nvectors =prepare_data(books)\r\n\r\nfor i in range(0,len(best_books)):\r\n    sim_books = find_similar_books (best_books[i],books,new_books,vectors)\r\n    sim_books = sim_books[0:1]\r\n    for idx,score in sim_books:\r\n        isbn_val = books.iloc[idx]['ISBN']\r\n        print(isbn_val in books_old['ISBN'].values)\r\n\r\n    \r\n\r\n#run predict \r\n#for i in best_books:\r\n    #if (i in books_old['ISBN'].values):\r\n        #input_path = '/kaggle/input/booksusers'\r\n        #predict(276762, str(i), input_path)\r\n'''","metadata":{"_uuid":"d4476a1a-ddc7-488b-b9f8-9c4b83395433","_cell_guid":"ad976c10-ffac-4767-bd56-746329c4c294","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}